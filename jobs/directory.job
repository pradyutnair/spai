#!/bin/bash
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --cpus-per-task=16
#SBATCH --job-name=train_semantic_fusion
#SBATCH --output=/home/pnair/spai/jobs/job_outputs/train_semantic_fusion.log
#SBATCH --time=04:00:00
##SBATCH --mem=180G
#SBATCH --hint=nomultithread

echo "‚úÖ Job started at: $(date)"
echo "üéØ Training SPAI with Enhanced Semantic-Spectral Fusion"
module purge
module load 2023
module load Anaconda3/2023.07-2
module load CUDA/12.1.1

source activate spai

cd /home/pnair/spai
#pip install -r requirements.txt
#pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121
export NEPTUNE_API_TOKEN="eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlZDBmOTg4MS04MTU0LTQ4YTItYTI1Mi1lNjdjZjhiMzJkMzAifQ==" 
export NEPTUNE_PROJECT="spai/beast-mode"
export PYTHONPATH=$PYTHONPATH:/home/pnair/spai
export NCCL_DEBUG=INFO
export CUDA_LAUNCH_BLOCKING=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# python /home/pnair/spai/spai/tools/create_dmid_ldm_train_val_csv.py \
#   --train_dir "/scratch-shared/dl2_spai/datasets/latent_diffusion_trainingset/train" \
#   --val_dir "/scratch-shared/dl2_spai/datasets/latent_diffusion_trainingset/valid" \
#   --coco_dir "/scratch-shared/dl2_spai/datasets/coco/images" \
#   --lsun_dir "/scratch-shared/dl2_spai_datasets/LSUN/lsun/scenes/" \
#   -o "/home/pnair/spai/datasets/ldm_train_val_lsun.csv" 

# python /home/pnair/spai/spai/tools/create_dmid_ldm_train_val_csv_copy.py \
#   --lsun_dir "/scratch-shared/dl2_spai_datasets/LSUN/lsun/scenes/" \
#   -o "/home/pnair/spai/datasets/lsun_train_val_lsun_test.csv"

# python /home/pnair/spai/spai/tools/augment_dataset.py \
#   --cfg ./configs/vit_base/vit_base__multipatch__100ep__intermediate__restore__patch_proj_per_feature__last_proj_layer_no_activ__fre_orig_branch__all_layers__bce_loss__light_augmentations.yaml \
#   -c ./datasets/ldm_val.csv \
#   -o ./datasets/ldm_val_augm.csv \
#   -d ./datasets/latent_diffusion_trainingset_augm

echo "üöÄ Starting enhanced semantic-spectral fusion training..."
python -m spai train \
  --cfg "/home/pnair/spai/configs/spai.yaml" \
  --batch-size 16 \
  --pretrained "/home/pnair/spai/weights/spai.pth" \
  --output "/home/pnair/spai/output/train_semantic_fusion_enhanced" \
  --data-path "/home/pnair/spai/datasets/ldm_lsun_train_val_subset.csv" \
  --tag "semantic_fusion_enhanced" \
  --amp-opt-level "O2" \
  --data-workers 8 \
  --save-all \
  --opt "DATA.VAL_BATCH_SIZE" "128" \
  --opt "MODEL.FEATURE_EXTRACTION_BATCH" "200" \
  --opt "DATA.TEST_PREFETCH_FACTOR" "2" \
  --opt "DATA.AUGMENTED_VIEWS" "4"

# echo "üîç Testing FLUX"

# # FLUX
# python -m spai test \
#   --cfg "/home/pnair/spai/configs/spai.yaml" \
#   --batch-size 8 \
#   --model "/home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth" \
#   --output "/home/pnair/spai/output_prad_trained_spai/test" \
#   --tag "spai" \
#   --opt "MODEL.PATCH_VIT.MINIMUM_PATCHES" "4" \
#   --opt "DATA.NUM_WORKERS" "8" \
#   --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
#   --opt "DATA.TEST_PREFETCH_FACTOR" "1" \
#   --test-csv "/home/pnair/spai/datasets/test_set_flux_no_imagenet.csv"

# echo "üîç Testing GIGAGAN"
# # # GIGAGAN
# python -m spai test \
#   --cfg "/home/pnair/spai/configs/spai.yaml" \
#   --batch-size 8 \
#   --model "/home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth" \
#   --output "/home/pnair/spai/output_prad_trained_spai/test" \
#   --tag "spai" \
#   --opt "MODEL.PATCH_VIT.MINIMUM_PATCHES" "4" \
#   --opt "DATA.NUM_WORKERS" "8" \
#   --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
#   --opt "DATA.TEST_PREFETCH_FACTOR" "1" \
#   --test-csv "/home/pnair/spai/datasets/test_set_gigagan_no_imagenet.csv"

# echo "üîç Testing MIDJOURNEY-V6.1"
# # MIDJOURNEY-V6.1
# python -m spai test \
#   --cfg "/home/pnair/spai/configs/spai.yaml" \
#   --batch-size 8 \
#   --model "/home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth" \
#   --output "/home/pnair/spai/output_prad_trained_spai/test" \
#   --tag "spai" \
#   --opt "MODEL.PATCH_VIT.MINIMUM_PATCHES" "4" \
#   --opt "DATA.NUM_WORKERS" "8" \
#   --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
#   --opt "DATA.TEST_PREFETCH_FACTOR" "1" \
#   --test-csv "/home/pnair/spai/datasets/test_set_midjourney-v6.1_no_imagenet.csv"

# echo "üîç Testing SD3"
# python -m spai test \
#   --cfg "/home/pnair/spai/configs/spai.yaml" \
#   --batch-size 8 \
#   --model "/home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth" \
#   --output "/home/pnair/spai/output_prad_trained_spai/test" \
#   --tag "spai" \
#   --opt "MODEL.PATCH_VIT.MINIMUM_PATCHES" "4" \
#   --opt "DATA.NUM_WORKERS" "8" \
#   --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
#   --opt "DATA.TEST_PREFETCH_FACTOR" "1" \
#   --test-csv "/home/pnair/spai/datasets/test_set_sd3_fixed_no_imagenet.csv"

# echo "üîç Testing ARTIFACT"
# python -m spai test \
#   --cfg "/home/pnair/spai/configs/spai.yaml" \
#   --batch-size 8 \
#   --model "/home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth" \
#   --output "/home/pnair/spai/output_prad_trained_spai/test" \
#   --tag "spai" \
#   --opt "MODEL.PATCH_VIT.MINIMUM_PATCHES" "4" \
#   --opt "DATA.NUM_WORKERS" "8" \
#   --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
#   --opt "DATA.TEST_PREFETCH_FACTOR" "1" \
#   --test-csv "/home/pnair/spai/datasets/artifact_test.csv"

# echo "üîç Testing LSUN"
# python -m spai test \
#   --cfg "/home/pnair/spai/configs/spai.yaml" \
#   --batch-size 8 \
#   --model "/home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth" \
#   --output "/home/pnair/spai/output_prad_trained_spai/test" \
#   --tag "spai" \
#   --opt "MODEL.PATCH_VIT.MINIMUM_PATCHES" "4" \
#   --opt "DATA.NUM_WORKERS" "8" \
#   --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
#   --opt "DATA.TEST_PREFETCH_FACTOR" "1" \
#   --test-csv "/home/pnair/spai/datasets/lsun_test.csv"

# # SD3-5
echo "‚úÖ Training completed at: $(date)"