#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --gpus=1
#SBATCH --output="outputs/train_please_dino_work_%A.out"
#SBATCH --partition=gpu_h100
#SBATCH --time=04:00:00
#SBATCH --mem=180G
cd $HOME/spai

module purge
module load 2023
module load Anaconda3/2023.07-2

export NEPTUNE_API_TOKEN="get your own key! >:("


# Setup 
# conda create -n spai python=3.11
conda activate spai
# pip install filetype
# conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia
# pip install -r requirements.txt
# pip install open_clip_torch
# pip install jsonschema
# Inference
# srun python -m spai --help

srun python -m spai train \
  --cfg "./configs/spai.yaml" \
  --batch-size 512 \
  --pretrained "weights/spai.pth" \
  --output "/scratch-shared/dl2_spai_datasets/weights/train_dinov2" \
  --data-path "/home/scur2620/spai/chameleon_dataset_split.csv" \
  --tag "spai_dino" \
  --amp-opt-level "O0" \
  --data-workers 8 \
  --save-all \
  --opt "DATA.VAL_BATCH_SIZE" "512" \
  --opt "MODEL.FEATURE_EXTRACTION_BATCH" "400" \
  --opt "DATA.TEST_PREFETCH_FACTOR" "1" \

# --pretrained "./weights/mfm_pretrain_vit_base.pth" \ 
